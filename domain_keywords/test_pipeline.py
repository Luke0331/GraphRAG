#!/usr/bin/env python3
"""
ç¡…ç”µæ± é¢†åŸŸè¯å…¸æå–Pipelineæµ‹è¯•è„šæœ¬
éªŒè¯å„ä¸ªæ­¥éª¤çš„åŸºæœ¬åŠŸèƒ½
"""

import os
import sys
from pathlib import Path
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_dependencies():
    """æµ‹è¯•ä¾èµ–åŒ…æ˜¯å¦å®‰è£…"""
    logger.info("ğŸ” æµ‹è¯•ä¾èµ–åŒ…...")
    
    required_packages = {
        'PyMuPDF': 'fitz',
        'keybert': 'keybert',
        'sentence-transformers': 'sentence_transformers',
        'pandas': 'pandas',
        'openpyxl': 'openpyxl'
    }
    
    missing_packages = []
    
    for package_name, import_name in required_packages.items():
        try:
            __import__(import_name)
            logger.info(f"âœ… {package_name}")
        except ImportError:
            logger.error(f"âŒ {package_name} - æœªå®‰è£…")
            missing_packages.append(package_name)
    
    if missing_packages:
        logger.error(f"ç¼ºå°‘ä¾èµ–åŒ…: {', '.join(missing_packages)}")
        logger.info("è¯·è¿è¡Œ: pip install -r requirements_dictionary.txt")
        return False
    
    logger.info("âœ… æ‰€æœ‰ä¾èµ–åŒ…å·²å®‰è£…")
    return True

def test_file_structure():
    """æµ‹è¯•æ–‡ä»¶ç»“æ„"""
    logger.info("ğŸ” æµ‹è¯•æ–‡ä»¶ç»“æ„...")
    
    # æ£€æŸ¥è„šæœ¬æ–‡ä»¶
    script_files = [
        'step1_pdf_to_text.py',
        'step2_keyword_extraction.py', 
        'step3_create_spreadsheet.py',
        'step4_generate_json.py',
        'run_pipeline.py'
    ]
    
    missing_scripts = []
    for script in script_files:
        if Path(script).exists():
            logger.info(f"âœ… {script}")
        else:
            logger.error(f"âŒ {script} - æ–‡ä»¶ä¸å­˜åœ¨")
            missing_scripts.append(script)
    
    if missing_scripts:
        logger.error(f"ç¼ºå°‘è„šæœ¬æ–‡ä»¶: {', '.join(missing_scripts)}")
        return False
    
    # æ£€æŸ¥PDFç›®å½•
    pdf_dir = Path("../zotero")
    if pdf_dir.exists():
        pdf_files = list(pdf_dir.glob("*.pdf"))
        logger.info(f"âœ… PDFç›®å½•å­˜åœ¨ï¼ŒåŒ…å« {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
    else:
        logger.error("âŒ PDFç›®å½•ä¸å­˜åœ¨: ../zotero")
        return False
    
    logger.info("âœ… æ–‡ä»¶ç»“æ„æ£€æŸ¥é€šè¿‡")
    return True

def test_pdf_extraction():
    """æµ‹è¯•PDFæ–‡æœ¬æå–åŠŸèƒ½"""
    logger.info("ğŸ” æµ‹è¯•PDFæ–‡æœ¬æå–...")
    
    try:
        import fitz
        from pathlib import Path
        
        # æŸ¥æ‰¾ä¸€ä¸ªPDFæ–‡ä»¶è¿›è¡Œæµ‹è¯•
        pdf_dir = Path("../zotero")
        pdf_files = list(pdf_dir.glob("*.pdf"))
        
        if not pdf_files:
            logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°PDFæ–‡ä»¶")
            return False
        
        # æµ‹è¯•ç¬¬ä¸€ä¸ªPDFæ–‡ä»¶
        test_pdf = pdf_files[0]
        logger.info(f"æµ‹è¯•æ–‡ä»¶: {test_pdf.name}")
        
        doc = fitz.open(test_pdf)
        text_content = []
        
        # åªè¯»å–å‰3é¡µè¿›è¡Œæµ‹è¯•
        for page_num in range(min(3, len(doc))):
            page = doc.load_page(page_num)
            text = page.get_text()
            if text.strip():
                text_content.append(text)
        
        doc.close()
        
        if text_content:
            logger.info(f"âœ… PDFæ–‡æœ¬æå–æˆåŠŸï¼Œæå–äº† {len(text_content)} é¡µå†…å®¹")
            logger.info(f"   æ–‡æœ¬é•¿åº¦: {sum(len(text) for text in text_content)} å­—ç¬¦")
            return True
        else:
            logger.error("âŒ PDFæ–‡æœ¬æå–å¤±è´¥ï¼Œæ²¡æœ‰æå–åˆ°å†…å®¹")
            return False
            
    except Exception as e:
        logger.error(f"âŒ PDFæ–‡æœ¬æå–æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def test_keyword_extraction():
    """æµ‹è¯•å…³é”®è¯æå–åŠŸèƒ½"""
    logger.info("ğŸ” æµ‹è¯•å…³é”®è¯æå–...")
    
    try:
        from keybert import KeyBERT
        from sentence_transformers import SentenceTransformer
        
        # æµ‹è¯•æ–‡æœ¬
        test_text = """
        Silicon heterojunction solar cells have achieved remarkable efficiency improvements 
        through advanced passivation techniques and optimized carrier transport. 
        The PERC technology demonstrates superior performance in commercial applications.
        Anti-reflection coatings enhance light absorption and improve conversion efficiency.
        """
        
        # åŠ è½½æ¨¡å‹
        model = SentenceTransformer('all-MiniLM-L6-v2')
        kw_model = KeyBERT(model=model)
        
        # æå–å…³é”®è¯
        keywords = kw_model.extract_keywords(
            test_text,
            keyphrase_ngram_range=(1, 3),
            stop_words='english',
            use_mmr=True,
            top_n=10
        )
        
        if keywords:
            logger.info(f"âœ… å…³é”®è¯æå–æˆåŠŸï¼Œæå–äº† {len(keywords)} ä¸ªå…³é”®è¯")
            logger.info(f"   ç¤ºä¾‹å…³é”®è¯: {[kw[0] for kw in keywords[:5]]}")
            return True
        else:
            logger.error("âŒ å…³é”®è¯æå–å¤±è´¥")
            return False
            
    except Exception as e:
        logger.error(f"âŒ å…³é”®è¯æå–æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def test_excel_operations():
    """æµ‹è¯•Excelæ“ä½œåŠŸèƒ½"""
    logger.info("ğŸ” æµ‹è¯•Excelæ“ä½œ...")
    
    try:
        import pandas as pd
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = {
            'Candidate_Term': ['silicon heterojunction', 'perc cell', 'anti-reflection coating'],
            'Is_Keep': [1, 1, 1],
            'Standard_Name': ['Silicon Heterojunction', 'PERC Cell', 'Anti-Reflection Coating'],
            'Category': ['Technology', 'Technology', 'Process']
        }
        
        df = pd.DataFrame(test_data)
        
        # æµ‹è¯•ä¿å­˜Excel
        test_file = 'test_excel.xlsx'
        df.to_excel(test_file, index=False)
        
        # æµ‹è¯•è¯»å–Excel
        df_read = pd.read_excel(test_file)
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        Path(test_file).unlink()
        
        if len(df_read) == len(df):
            logger.info("âœ… Excelæ“ä½œæµ‹è¯•æˆåŠŸ")
            return True
        else:
            logger.error("âŒ Excelæ“ä½œæµ‹è¯•å¤±è´¥")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Excelæ“ä½œæµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸ§ª å¼€å§‹PipelineåŠŸèƒ½æµ‹è¯•")
    logger.info("=" * 50)
    
    tests = [
        ("ä¾èµ–åŒ…æ£€æŸ¥", test_dependencies),
        ("æ–‡ä»¶ç»“æ„æ£€æŸ¥", test_file_structure),
        ("PDFæ–‡æœ¬æå–", test_pdf_extraction),
        ("å…³é”®è¯æå–", test_keyword_extraction),
        ("Excelæ“ä½œ", test_excel_operations)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        logger.info(f"\nğŸ“‹ {test_name}")
        try:
            if test_func():
                passed += 1
            else:
                logger.error(f"âŒ {test_name} å¤±è´¥")
        except Exception as e:
            logger.error(f"âŒ {test_name} å¼‚å¸¸: {str(e)}")
    
    logger.info("=" * 50)
    logger.info(f"ğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Pipelineå¯ä»¥æ­£å¸¸è¿è¡Œ")
        logger.info("ğŸ’¡ è¿è¡Œå‘½ä»¤: python run_pipeline.py")
    else:
        logger.error("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®")
    
    return passed == total

if __name__ == "__main__":
    main() 