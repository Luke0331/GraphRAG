import json
import os
import re
import time
from typing import List, Dict, Any
from collections import defaultdict

# LangChain imports
from langchain_community.retrievers import LlamaIndexRetriever
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
# from langchain_community.llms import ZhipuAI
from llama_index.llms.zhipuai import ZhipuAI
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_core.documents import Document as LCDocument
from langchain_core.retrievers import BaseRetriever

# LlamaIndex imports (for compatibility)
from llama_index.core import (
    Document, 
    VectorStoreIndex, 
    StorageContext,
    Settings
)
from llama_index.vector_stores.deeplake import DeepLakeVectorStore # Make sure this is imported
from llama_index.llms.zhipuai import ZhipuAI as LlamaIndexZhipuAI

# Custom embedding solution
from embedding_solution import create_embedding_model
from langchain_core.language_models.llms import LLM
from pydantic import PrivateAttr

from custom_prompt_templates import PromptTemplateManager

class LangChainZhipuAI(LLM):
    _llm: ZhipuAI = PrivateAttr()

    def __init__(self, api_key, model, **kwargs):
        super().__init__(**kwargs)
        self._llm = ZhipuAI(api_key=api_key, model=model)

    def _call(self, prompt, stop=None, run_manager=None, **kwargs):
        return self._llm.complete(prompt).text

    @property
    def _llm_type(self):
        return "zhipuai"

class LlamaIndexRetrieverAdapter(BaseRetriever):
    _llama_retriever: any = PrivateAttr()

    def __init__(self, llama_retriever, **kwargs):
        super().__init__(**kwargs)
        self._llama_retriever = llama_retriever

    def _get_relevant_documents(self, query, *, run_manager=None, **kwargs):
        # è·å–kå‚æ•°ï¼Œé»˜è®¤ä¸º5
        k = kwargs.get('k', 5)
        # è®¾ç½®æ£€ç´¢å™¨çš„top_k
        self._llama_retriever.similarity_top_k = k
        nodes = self._llama_retriever.retrieve(query)
        return [LCDocument(page_content=node.text, metadata=node.metadata) for node in nodes]

    def _call(self, query, **kwargs):
        return self._get_relevant_documents(query, **kwargs)

class LangChainDomainRAG:
    """
    åŸºäºLangChain RetrievalQAçš„é¢†åŸŸæ„ŸçŸ¥RAGç³»ç»Ÿ
    """
    
    def __init__(self, 
                 domain_dict_path: str = "domain_keywords/domain_dictionary.json",
                 vector_store_path: str = "RAG-Wikipedia/dataset/vector_storage_new",
                 llm_api_key: str = "41b29e65745d4110a018c5d616b0012f.A6CEwmornnYXSVLC",
                 llm_model: str = "glm-4-flash"):
        """
        åˆå§‹åŒ–LangChainé¢†åŸŸæ„ŸçŸ¥RAGç³»ç»Ÿ
        
        Args:
            domain_dict_path: é¢†åŸŸè¯å…¸æ–‡ä»¶è·¯å¾„
            vector_store_path: å‘é‡å­˜å‚¨è·¯å¾„
            llm_api_key: LLM APIå¯†é’¥
            llm_model: LLMæ¨¡å‹åç§°
        """
        self.domain_dict_path = domain_dict_path
        self.vector_store_path = vector_store_path
        
        # prompt templates
        self.prompt_manager = PromptTemplateManager()

        # åŠ è½½é¢†åŸŸè¯å…¸
        self.domain_dictionary = self._load_domain_dictionary()

        # è®¾ç½®æœ¬åœ° embedding æ¨¡å‹
        model_path = r"F:\Intern\EDF\EmbeddingModels\Qwen3-Embedding-0.6B"
        embed_model = create_embedding_model(model_path, fallback=True)
        Settings.embed_model = embed_model
        
        # åˆå§‹åŒ–LlamaIndexç´¢å¼•ï¼ˆç”¨äºLangChainæ£€ç´¢å™¨ï¼‰
        self._initialize_llama_index()
        
        # åˆå§‹åŒ–LangChainç»„ä»¶
        self._initialize_langchain_components(llm_api_key, llm_model)
        
        print(f"âœ“ é¢†åŸŸè¯å…¸åŠ è½½å®Œæˆï¼Œå…± {len(self.domain_dictionary)} ä¸ªæœ¯è¯­")
        print(f"âœ“ LangChain RetrievalQAåˆå§‹åŒ–å®Œæˆ")
        print(f"âœ“ å‘é‡å­˜å‚¨è·¯å¾„: {vector_store_path}")
    
    def _load_domain_dictionary(self) -> Dict[str, Dict[str, Any]]:
        """åŠ è½½é¢†åŸŸè¯å…¸"""
        try:
            with open(self.domain_dict_path, 'r', encoding='utf-8') as f:
                domain_dict = json.load(f)
            
            processed_dict = {}
            for item in domain_dict:
                standard_name = item.get('standard_name', '')
                aliases = item.get('aliases', [])
                category = item.get('category', '')
                
                processed_dict[standard_name] = {
                    'aliases': aliases,
                    'category': category,
                    'all_terms': [standard_name] + aliases
                }
            
            return processed_dict
            
        except Exception as e:
            print(f"âœ— åŠ è½½é¢†åŸŸè¯å…¸å¤±è´¥: {e}")
            return {}
    
    def _initialize_llama_index(self):
        """åˆå§‹åŒ–LlamaIndexç´¢å¼•"""
        try:
            # Reverted to the correct DeepLake loading logic
            print(f"ğŸ’¾ Loading DeepLake index from path: {self.vector_store_path}")
            vector_store = DeepLakeVectorStore(dataset_path=self.vector_store_path, read_only=True)
            storage_context = StorageContext.from_defaults(vector_store=vector_store)
            
            self.index = VectorStoreIndex.from_vector_store(
                vector_store,
                storage_context=storage_context
            )
            self.retriever = self.index.as_retriever()
            
            print("âœ“ LlamaIndexç´¢å¼•åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âœ— LlamaIndexç´¢å¼•åˆå§‹åŒ–å¤±è´¥: {e}")
            self.index = None
            self.retriever = None
    
    def _initialize_langchain_components(self, llm_api_key: str, llm_model: str):
        """åˆå§‹åŒ–LangChainç»„ä»¶"""
        try:
            if self.retriever is None:
                raise RuntimeError("LlamaIndex retriever åˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•åˆ›å»º LangChain æ£€ç´¢å™¨ã€‚")
        
            # åˆ›å»ºLangChainæ£€ç´¢å™¨ 
            self.lc_retriever = LlamaIndexRetrieverAdapter(self.retriever)

            # åˆ›å»ºLangChain LLM
            self.llm = LangChainZhipuAI(
                api_key=llm_api_key,
                model=llm_model
            )
            
            # åˆ›å»ºè‡ªå®šä¹‰æç¤ºæ¨¡æ¿
            # self.prompt_template = PromptTemplate(
            #     input_variables=["context", "question"],
            #     template="""
            #     ä½ æ˜¯ä¸€ä¸ªç¡…ç”µæ± é¢†åŸŸçš„ä¸“å®¶åŠ©æ‰‹ã€‚åŸºäºä»¥ä¸‹ç›¸å…³æ–‡æ¡£ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
                
            #     ç›¸å…³æ–‡æ¡£:
            #     {context}
                
            #     ç”¨æˆ·é—®é¢˜: {question}
                
            #     è¯·æä¾›å‡†ç¡®ã€è¯¦ç»†çš„ç­”æ¡ˆï¼Œå¼•ç”¨æ–‡æ¡£ä¸­çš„å…·ä½“ä¿¡æ¯ï¼Œå¹¶æä¾›å¼•ç”¨æ–‡æ¡£çš„è¯¦ç»†ä¿¡æ¯ã€‚
                
            #     ç­”æ¡ˆ:
            #     """
            # )
            self.prompt_template = self.prompt_manager.get_prompt("qa")
            
            # åˆ›å»ºRetrievalQAé“¾
            self.qa_chain = RetrievalQA.from_chain_type(
                llm=self.llm,
                chain_type="stuff",
                retriever=self.lc_retriever,
                chain_type_kwargs={
                    "prompt": self.prompt_template
                },
                verbose=True
            )
            
            print("âœ“ LangChainç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âœ— LangChainç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _extract_domain_terms(self, query: str) -> List[str]:
        """ä»æŸ¥è¯¢ä¸­æå–é¢†åŸŸæœ¯è¯­"""
        extracted_terms = []
        query_lower = query.lower()
        
        for standard_name, term_info in self.domain_dictionary.items():
            all_terms = term_info['all_terms']
            
            for term in all_terms:
                if term.lower() in query_lower:
                    extracted_terms.append(standard_name)
                    break
        
        return list(set(extracted_terms))
    
    def _expand_query_with_domain_terms(self, query: str) -> str:
        """ä½¿ç”¨é¢†åŸŸæœ¯è¯­æ‰©å±•æŸ¥è¯¢"""
        extracted_terms = self._extract_domain_terms(query)
        
        if not extracted_terms:
            return query
        
        expansion_parts = []
        for term in extracted_terms:
            term_info = self.domain_dictionary[term]
            aliases = term_info['aliases']
            expansion_parts.extend(aliases)
        
        expansion_terms = list(set(expansion_parts))[:10]
        
        if expansion_terms:
            expanded_query = f"{query} {' '.join(expansion_terms)}"
            print(f"ğŸ” æŸ¥è¯¢æ‰©å±•: {query} -> {expanded_query}")
            return expanded_query
        
        return query

    def _rewrite_query_with_domain_context(self, query: str) -> str:
        """
        ä½¿ç”¨é¢†åŸŸä¸Šä¸‹æ–‡é‡å†™æŸ¥è¯¢
        Args:
            query: åŸå§‹æŸ¥è¯¢
        Returns:
            é‡å†™åçš„æŸ¥è¯¢
        """
        extracted_terms = self._extract_domain_terms(query)
        if not extracted_terms:
            return query
        # æ„å»ºé¢†åŸŸä¸Šä¸‹æ–‡æç¤º
        context_parts = []
        for term in extracted_terms[:3]:  # æœ€å¤š3ä¸ªä¸»è¦æœ¯è¯­
            term_info = self.domain_dictionary[term]
            category = term_info['category']
            context_parts.append(f"{term} ({category})")
        context = ", ".join(context_parts)
        # ä½¿ç”¨LLMé‡å†™æŸ¥è¯¢
        prompt = f"""
        åŸºäºä»¥ä¸‹ç¡…ç”µæ± é¢†åŸŸæœ¯è¯­çš„ä¸Šä¸‹æ–‡ï¼Œé‡å†™ç”¨æˆ·æŸ¥è¯¢ä»¥æ›´å¥½åœ°åŒ¹é…ç›¸å…³æ–‡æ¡£ï¼š
        é¢†åŸŸä¸Šä¸‹æ–‡: {context}
        ç”¨æˆ·æŸ¥è¯¢: {query}
        è¯·é‡å†™æŸ¥è¯¢ï¼Œä¿æŒåŸæ„ä½†ä½¿ç”¨æ›´å‡†ç¡®çš„é¢†åŸŸæœ¯è¯­ã€‚åªè¿”å›é‡å†™åçš„æŸ¥è¯¢ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
        """
        try:
            rewritten_query = self.llm._call(prompt).strip()
            print(f"ğŸ”„ æŸ¥è¯¢é‡å†™: {query} -> {rewritten_query}")
            return rewritten_query
        except Exception as e:
            print(f"âš ï¸ æŸ¥è¯¢é‡å†™å¤±è´¥: {e}")
            return query

    def _translate_to_english(self, text: str) -> str:
        """
        ç”¨ LLM æŠŠè¾“å…¥ç¿»è¯‘æˆè‹±æ–‡
        """
        prompt = f"Translate the following text to English. Only return the translation:\n{text}"
        try:
            if hasattr(self.llm, "complete"):
                return self.llm.complete(prompt).text.strip()
            else:
                return self.llm._call(prompt).strip()
        except Exception as e:
            print(f"âš ï¸ è‹±æ–‡ç¿»è¯‘å¤±è´¥: {e}")
            return text

    def _translate_to_chinese(self, text: str) -> str:
        """
        ç”¨ LLM æŠŠè¾“å…¥ç¿»è¯‘æˆä¸­æ–‡
        """
        prompt = f"è¯·å°†ä¸‹åˆ—å†…å®¹ç¿»è¯‘æˆä¸­æ–‡ï¼Œåªè¿”å›ç¿»è¯‘ç»“æœï¼š\n{text}"
        try:
            if hasattr(self.llm, "complete"):
                return self.llm.complete(prompt).text.strip()
            else:
                return self.llm._call(prompt).strip()
        except Exception as e:
            print(f"âš ï¸ ä¸­æ–‡ç¿»è¯‘å¤±è´¥: {e}")
            return text


    def _extract_structured_query(self, user_query: str) -> Dict[str, str]:
        prompt = f"""
        è¯·ä»ä¸‹åˆ—é—®é¢˜ä¸­æå–å‡ºææ–™åç§°ã€æŒ‡æ ‡å’Œå…³ç³»ï¼Œè¿”å›JSONæ ¼å¼ï¼Œå¦‚ï¼š{{"material": "...", "metric": "...", "relation": "..."}}
        é—®é¢˜ï¼š{user_query}
        åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
        """
        try:
            result = self.llm._call(prompt)
            print(f"LLMç»“æ„åŒ–æŠ½å–åŸå§‹è¿”å›: {result!r}")
            # å°è¯•ç”¨æ­£åˆ™æå–JSON
            match = re.search(r'\{.*\}', result, re.DOTALL)
            if match:
                return json.loads(match.group(0))
            else:
                print("æœªæ‰¾åˆ°JSONç»“æ„ï¼Œè¿”å›ç©º")
                return {}
        except Exception as e:
            print(f"ç»“æ„åŒ–æŠ½å–å¤±è´¥: {e}")
            return {}

    def _structured_retrieve(self, structured_query: Dict[str, str], top_k: int = 5) -> str:
        """
        ç”¨ç»“æ„åŒ–æ¡ä»¶æ£€ç´¢æ–‡æ¡£ã€‚è¿™é‡Œç®€å•ç”¨ANDå…³é”®è¯è¿‡æ»¤ï¼Œä¹Ÿå¯æ‰©å±•ä¸ºå¤šå­—æ®µæ£€ç´¢ã€‚
        è¿”å›æ‹¼æ¥åçš„æ–‡æ¡£å†…å®¹å­—ç¬¦ä¸²ã€‚
        """
        # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…åº”ç”¨å¯ç”¨æ›´å¤æ‚çš„æ£€ç´¢é€»è¾‘
        keywords = [v for v in structured_query.values() if v]
        # å‡è®¾æœ‰ self.index/documentsï¼Œæˆ–ç”¨ retriever æ”¯æŒå¤šå…³é”®è¯
        # è¿™é‡Œç›´æ¥ç”¨åŸæœ‰æ£€ç´¢å™¨åšä¸€æ¬¡å¤šå…³é”®è¯æ‹¼æ¥
        query = " ".join(keywords)
        docs = self.lc_retriever._get_relevant_documents(query)
        context = "\n".join([doc.page_content for doc in docs[:top_k]])
        return context

    # def query(self, 
    #           user_query: str, 
    #           use_query_expansion: bool = True,
    #           use_query_rewriting: bool = True,
    #           top_k: int = 5,
    #           prompt_type: str = "qa",
    #           use_structured_query: bool = False) -> Dict[str, Any]:
    #     """
    #     æ‰§è¡ŒLangChain RetrievalQAæŸ¥è¯¢
    #     Args:
    #         user_query: ç”¨æˆ·æŸ¥è¯¢
    #         use_query_expansion: æ˜¯å¦ä½¿ç”¨æŸ¥è¯¢æ‰©å±•
    #         use_query_rewriting: æ˜¯å¦ä½¿ç”¨æŸ¥è¯¢é‡å†™
    #         top_k: æ£€ç´¢æ–‡æ¡£æ•°é‡
    #         prompt_typeï¼šé—®ç­”ç±»å‹
    #         use_structured_query: æ˜¯å¦ä½¿ç”¨ç»“æ„åŒ–æ£€ç´¢
    #     Returns:
    #         æŸ¥è¯¢ç»“æœå­—å…¸
    #     """
    #     start_time = time.time()
    #     print(f"\nğŸ” å¤„ç†æŸ¥è¯¢: {user_query}")
    #     print("="*50)

    #     # 0. ç¿»è¯‘
    #     user_query = self._translate_to_english(user_query)
    #     print(f"ğŸŒ ç¿»è¯‘åè‹±æ–‡æŸ¥è¯¢: {user_query}")

    #     # 1. æå–é¢†åŸŸæœ¯è¯­
    #     domain_terms = self._extract_domain_terms(user_query)
    #     print(f"ğŸ“š æå–çš„é¢†åŸŸæœ¯è¯­: {domain_terms}")

    #     # 2. æŸ¥è¯¢æ‰©å±•
    #     expanded_query = user_query
    #     if use_query_expansion and domain_terms:
    #         expanded_query = self._expand_query_with_domain_terms(user_query)
        
    #     # 3. æŸ¥è¯¢é‡å†™
    #     final_query = expanded_query
    #     if use_query_rewriting and domain_terms:
    #         final_query = self._rewrite_query_with_domain_context(expanded_query)
        
    #     # 4. ä½¿ç”¨LangChain RetrievalQAæ‰§è¡ŒæŸ¥è¯¢
    #     print(f"ğŸ” ä½¿ç”¨LangChain RetrievalQAæŸ¥è¯¢: {final_query}")
    #     try:
    #         # 1. åŠ¨æ€è·å–æ¨¡æ¿
    #         self.prompt_template = self.prompt_manager.get_prompt(prompt_type)

    #         # 2. åŠ¨æ€é‡å»º RetrievalQA é“¾ï¼ˆå¯é€‰ä¼˜åŒ–ï¼šåªåœ¨prompt_typeå˜åŒ–æ—¶é‡å»ºï¼‰
    #         self.qa_chain = RetrievalQA.from_chain_type(
    #             llm=self.llm,
    #             chain_type="stuff",
    #             retriever=self.lc_retriever,
    #             chain_type_kwargs={
    #                 "prompt": self.prompt_template
    #             },
    #             verbose=True
    #         )

    #         # 3. æ‰§è¡ŒæŸ¥è¯¢
    #         response = self.qa_chain.invoke({"query": final_query})
    #         answer = response.get("result", "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç­”æ¡ˆã€‚")
    #     except Exception as e:
    #         print(f"âœ— LangChainæŸ¥è¯¢å¤±è´¥: {e}")
    #         answer = "æŠ±æ­‰ï¼ŒæŸ¥è¯¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ã€‚"

    #     # 5. ç­”æ¡ˆç¿»è¯‘å›ä¸­æ–‡
    #     answer_zh = self._translate_to_chinese(answer)
        
    #     # è®¡ç®—æ‰§è¡Œæ—¶é—´
    #     execution_time = time.time() - start_time
        
    #     # æ„å»ºç»“æœ
    #     result = {
    #         'original_query': user_query,
    #         'expanded_query': expanded_query,
    #         'final_query': final_query,
    #         'domain_terms': domain_terms,
    #         'answer': answer_zh,
    #         'execution_time': execution_time,
    #         'framework': 'LangChain RetrievalQA'
    #     }
    #     print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
    #     print("="*50)
    #     return result
    
    def query(self, 
            user_query: str, 
            use_query_expansion: bool = True,
            use_query_rewriting: bool = True,
            top_k: int = 5,
            prompt_type: str = "qa",
            use_structured_query: bool = False) -> Dict[str, Any]:
        start_time = time.time()
        print(f"\nğŸ” å¤„ç†æŸ¥è¯¢: {user_query}")
        print("="*50)

        # 0. ç¿»è¯‘
        user_query_en = self._translate_to_english(user_query)
        print(f"ğŸŒ ç¿»è¯‘åè‹±æ–‡æŸ¥è¯¢: {user_query_en}")

        if use_structured_query:
            # ç»“æ„åŒ–æ£€ç´¢åˆ†æ”¯
            structured_query = self._extract_structured_query(user_query_en)
            print(f"ğŸ§© ç»“æ„åŒ–æ£€ç´¢æ¡ä»¶: {structured_query}")
            context = self._structured_retrieve(structured_query, top_k=top_k)
            self.prompt_template = self.prompt_manager.get_prompt(prompt_type)
            prompt_text = self.prompt_template.format(context=context, question=user_query_en)
            try:
                answer = self.llm._call(prompt_text)
            except Exception as e:
                print(f"âœ— ç»“æ„åŒ–æ£€ç´¢å¤±è´¥: {e}")
                answer = "æŠ±æ­‰ï¼Œç»“æ„åŒ–æ£€ç´¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ã€‚"
            expanded_query = json.dumps(structured_query, ensure_ascii=False)
            final_query = expanded_query
            domain_terms = list(structured_query.values())
        else:
            # åŸæœ‰è‡ªç„¶è¯­è¨€æ£€ç´¢åˆ†æ”¯
            domain_terms = self._extract_domain_terms(user_query_en)
            print(f"ğŸ“š æå–çš„é¢†åŸŸæœ¯è¯­: {domain_terms}")

            expanded_query = user_query_en
            if use_query_expansion and domain_terms:
                expanded_query = self._expand_query_with_domain_terms(user_query_en)
            
            final_query = expanded_query
            if use_query_rewriting and domain_terms:
                final_query = self._rewrite_query_with_domain_context(expanded_query)
            
            print(f"ğŸ” ä½¿ç”¨LangChain RetrievalQAæŸ¥è¯¢: {final_query}")
            try:
                self.prompt_template = self.prompt_manager.get_prompt(prompt_type)
                self.qa_chain = RetrievalQA.from_chain_type(
                    llm=self.llm,
                    chain_type="stuff",
                    retriever=self.lc_retriever,
                    chain_type_kwargs={
                        "prompt": self.prompt_template
                    },
                    verbose=True
                )
                response = self.qa_chain.invoke({"query": final_query})
                answer = response.get("result", "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç­”æ¡ˆã€‚")
                
                # è·å–æ£€ç´¢åˆ°çš„æ–‡æ¡£ä¿¡æ¯ï¼Œä½¿ç”¨æŒ‡å®šçš„top_k
                retrieved_docs = self.lc_retriever.get_relevant_documents(final_query, k=top_k)
                source_docs = []
                for i, doc in enumerate(retrieved_docs):
                    source_info = {
                        "index": i + 1,
                        "content": doc.page_content,
                        "metadata": doc.metadata
                    }
                    source_docs.append(source_info)
                
            except Exception as e:
                print(f"âœ— LangChainæŸ¥è¯¢å¤±è´¥: {e}")
                answer = "æŠ±æ­‰ï¼ŒæŸ¥è¯¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ã€‚"
                source_docs = []

        # 5. ç­”æ¡ˆç¿»è¯‘å›ä¸­æ–‡
        answer_zh = self._translate_to_chinese(answer)
        execution_time = time.time() - start_time

        result = {
            'original_query': user_query_en,
            'expanded_query': expanded_query,
            'final_query': final_query,
            'domain_terms': domain_terms,
            'answer': answer_zh,
            'source_documents': source_docs,
            'retrieved_docs_count': len(source_docs),
            'execution_time': execution_time,
            'framework': 'LangChain RetrievalQA'
        }
        print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
        print("="*50)
        return result


    def get_domain_statistics(self) -> Dict[str, Any]:
        """è·å–é¢†åŸŸè¯å…¸ç»Ÿè®¡ä¿¡æ¯"""
        if not self.domain_dictionary:
            return {}
        
        categories = defaultdict(int)
        total_terms = len(self.domain_dictionary)
        total_aliases = 0
        
        for term_info in self.domain_dictionary.values():
            category = term_info['category']
            categories[category] += 1
            total_aliases += len(term_info['aliases'])
        
        return {
            'total_terms': total_terms,
            'total_aliases': total_aliases,
            'categories': dict(categories),
            'avg_aliases_per_term': total_aliases / total_terms if total_terms > 0 else 0
        }


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºLangChain RetrievalQAç³»ç»Ÿ"""
    # åˆå§‹åŒ–ç³»ç»Ÿ
    rag_system = LangChainDomainRAG()
    
    # æ˜¾ç¤ºé¢†åŸŸè¯å…¸ç»Ÿè®¡
    stats = rag_system.get_domain_statistics()
    print("\nğŸ“Š é¢†åŸŸè¯å…¸ç»Ÿè®¡:")
    print(f"æ€»æœ¯è¯­æ•°: {stats['total_terms']}")
    print(f"æ€»åŒä¹‰è¯æ•°: {stats['total_aliases']}")
    print(f"å¹³å‡åŒä¹‰è¯æ•°: {stats['avg_aliases_per_term']:.2f}")
    
    # ç¤ºä¾‹æŸ¥è¯¢
    test_queries = [
        "How to improve the efficiency of solar cells?",
        "What are the manufacturing processes of silicon cells?",
        "What is anti-reflective coating?",
        "How to measure the conversion efficiency of solar cells?"
    ]
    
    print("\n" + "="*60)
    print("ğŸ§ª æµ‹è¯•LangChain RetrievalQAç³»ç»Ÿ")
    print("="*60)
    
    for i, query in enumerate(test_queries, 1):
        print(f"\næµ‹è¯• {i}: {query}")
        result = rag_system.query(query)
        
        print(f"\nğŸ“ ç­”æ¡ˆ:")
        print(result['answer'])
        print(f"\nğŸ”§ æ¡†æ¶: {result['framework']}")


if __name__ == "__main__":
    main() 